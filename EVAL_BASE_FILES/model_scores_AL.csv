column,accuracy_at_5,precision_at_5,mrr_at_5,ndcg_at_5
llava_7b_output,0.7586206896551724,0.3862068965517242,0.5603448275862069,0.6114819818628788
minicpm_v_8b_output,0.7241379310344828,0.33793103448275863,0.5114942528735632,0.5547357509661875
bakllava_7b_output,0.7586206896551724,0.3586206896551724,0.45632183908045976,0.5385314977914927
reasoning_deepseek_reasoning_minicpm_v_8b_output,0.7241379310344828,0.39999999999999997,0.45632183908045976,0.5357415322846916
reasoning_llama3_1_intuitive_thinker_minicpm_v_8b_output,0.6785714285714286,0.35714285714285715,0.48928571428571427,0.5335690116338625
llama3_2_vision_11b_output,0.6896551724137931,0.33793103448275863,0.47413793103448276,0.5335366878383137
reasoning_deepseek_r1_abliterated_minicpm_v_8b_output,0.7241379310344828,0.303448275862069,0.4781609195402299,0.5294074229593253
reasoning_llama3_1_intuitive_thinker_llava_7b_output,0.7037037037037037,0.3333333333333333,0.45925925925925926,0.5262506611287675
llava_llama3_8b_output,0.6551724137931034,0.33793103448275863,0.46781609195402296,0.5164696295114086
reasoning_phi4_14b_minicpm_v_8b_output,0.6551724137931034,0.36551724137931035,0.47413793103448276,0.5081400688545132
granite3_2_vision_output,0.6551724137931034,0.3172413793103448,0.4494252873563218,0.4987480605796911
reasoning_phi4_14b_llava_7b_output,0.6896551724137931,0.31724137931034485,0.4235632183908046,0.4945506998183109
reasoning_deepseek_r1_abliterated_llava_7b_output,0.6551724137931034,0.3172413793103448,0.4482758620689655,0.4888524077038596
reasoning_phi4_14b_llama3_2_vision_11b_output,0.5862068965517241,0.2827586206896552,0.4425287356321839,0.4770223771107625
reasoning_deepseek_reasoning_llama3_2_vision_11b_output,0.5862068965517241,0.3103448275862069,0.4264367816091954,0.45268377175149194
gemma3_12b_output,0.5517241379310345,0.2620689655172414,0.4454022988505747,0.44585417459266274
reasoning_deepseek_reasoning_llava_7b_output,0.6206896551724138,0.27586206896551724,0.3816091954022988,0.4326403114590266
reasoning_deepseek_r1_abliterated_phi_14b_output,0.5517241379310345,0.26206896551724135,0.3931034482758621,0.4202649838123065
reasoning_deepseek_reasoning_gemma3_12b_output,0.4827586206896552,0.3103448275862069,0.38045977011494253,0.4050967870953486
reasoning_llama3_1_intuitive_thinker_llama3_2_vision_11b_output,0.5,0.2285714285714286,0.33749999999999997,0.3750250815326412
reasoning_deepseek_reasoning_phi_14b_output,0.5172413793103449,0.20689655172413793,0.314367816091954,0.37008380965277904
reasoning_deepseek_r1_abliterated_llama3_2_vision_11b_output,0.5517241379310345,0.22068965517241382,0.3074712643678161,0.3669613410392319
reasoning_phi4_14b_gemma3_12b_output,0.3793103448275862,0.18620689655172415,0.33448275862068966,0.33579152472339713
reasoning_llama3_1_intuitive_thinker_gemma3_12b_output,0.4782608695652174,0.1826086956521739,0.2927536231884058,0.3350579705426938
reasoning_phi4_14b_phi_14b_output,0.4827586206896552,0.1931034482758621,0.2793103448275862,0.3282226621920237
reasoning_llama3_1_intuitive_thinker_phi_14b_output,0.4230769230769231,0.1769230769230769,0.2897435897435897,0.3230581016130622
reasoning_deepseek_r1_abliterated_gemma3_12b_output,0.3448275862068966,0.16551724137931034,0.2528735632183908,0.26751904449515407
phi_14b_output,0.2413793103448276,0.06896551724137931,0.12183908045977011,0.15563749791755102
