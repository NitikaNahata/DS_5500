{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import lyricsgenius\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ✅ Credentials\n",
    "SPOTIFY_CLIENT_ID = \"968e5a07e9c74a74b2bf528d18f4c870\"\n",
    "SPOTIFY_CLIENT_SECRET = \"8439583339f54d13936b71bf490e4fa2\"\n",
    "GENIUS_API_KEY = \"ojzPuhVHc0uUz-6Usqc2SGeqe03s7tpURJ5FCb_QBjs4lEMRfcWyz4F6caQdDxIj\"\n",
    "\n",
    "# ✅ Initialize Genius client\n",
    "genius = lyricsgenius.Genius(GENIUS_API_KEY, timeout=15, retries=3)\n",
    "\n",
    "# ✅ Initialize theme classifier\n",
    "theme_classifier = pipeline(\"zero-shot-classification\", \n",
    "                          model=\"facebook/bart-large-mnli\")\n",
    "CANDIDATE_THEMES = [\n",
    "    \"romance\", \"sadness\", \"nature\", \"friendship\",\n",
    "    \"self-love\", \"meditation\", \"adventure\", \"nostalgia\",\n",
    "    \"party\", \"empowerment\", \"calm\", \"energy\"\n",
    "]\n",
    "\n",
    "def clean_lyrics(lyrics):\n",
    "    \"\"\"Remove section headers and clean text\"\"\"\n",
    "    return re.sub(r\"\\[.*?\\]\", \"\", lyrics).strip()\n",
    "\n",
    "def get_lyrics(track_name, artist_name):\n",
    "    \"\"\"Get cleaned lyrics using lyricsgenius\"\"\"\n",
    "    try:\n",
    "        song = genius.search_song(track_name, artist_name)\n",
    "        return clean_lyrics(song.lyrics) if song else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting lyrics for {track_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_themes(lyrics):\n",
    "    \"\"\"Analyze lyrics for themes using zero-shot classification\"\"\"\n",
    "    if not lyrics:  \n",
    "        return []\n",
    "    return theme_classifier(lyrics[:1000], CANDIDATE_THEMES)[\"labels\"][:3]\n",
    "\n",
    "def main():\n",
    "    # ✅ Load merged CSV file\n",
    "    df = pd.read_csv(\"supabase_user_playlist_features.csv\")  # Ensure the correct file path\n",
    "    df[\"lyrics\"] = None\n",
    "    df[\"themes\"] = None\n",
    "\n",
    "    songs_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        track_name = row[\"track_name\"]\n",
    "        artist_name = row[\"artist_name\"]\n",
    "        playlist_id = row[\"playlist_id\"]\n",
    "\n",
    "        print(f\"Processing: {track_name} - {artist_name}\")\n",
    "\n",
    "        # ✅ Get lyrics and analyze themes\n",
    "        lyrics = get_lyrics(track_name, artist_name)\n",
    "        themes = analyze_themes(lyrics) if lyrics else []\n",
    "\n",
    "        # ✅ Store results\n",
    "        songs_data.append({\n",
    "            \"track_id\": playlist_id,\n",
    "            \"track_name\": track_name,\n",
    "            \"artist_name\": artist_name,\n",
    "            \"lyrics\": lyrics,\n",
    "            \"themes\": themes\n",
    "        })\n",
    "\n",
    "        time.sleep(1)  # To avoid API rate limits\n",
    "\n",
    "    # ✅ Convert to DataFrame and save\n",
    "    lyrics_df = pd.DataFrame(songs_data)\n",
    "    lyrics_df.to_csv(\"merged_Csv_with_lyrics.csv\", index=False)\n",
    "    print(f\"Created database with {len(lyrics_df)} songs with lyrics and themes.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_csv_with_lyrics.csv\")\n",
    "\n",
    "# Remove duplicate rows (based on all columns)\n",
    "df_cleaned = df.drop_duplicates(subset=[\"playlist_id\",\"track_name\"])\n",
    "\n",
    "# OR remove duplicates based on specific columns (e.g., track_name and artist_name)\n",
    "# df_cleaned = df.drop_duplicates(subset=[\"track_name\", \"artist_name\"])\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv(\"lyrics_user_playlist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original rows: {len(df)}, Cleaned rows: {len(df_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_features = pd.read_csv(\"supabase_user_playlist_features.csv\")\n",
    "\n",
    "# Remove duplicate rows (based on all columns)\n",
    "df_user_features_cleaned = df_user_features.drop_duplicates(subset=[\"track_id\",\"track_name\"])\n",
    "\n",
    "# OR remove duplicates based on specific columns (e.g., track_name and artist_name)\n",
    "# df_cleaned = df.drop_duplicates(subset=[\"track_name\", \"artist_name\"])\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_user_features_cleaned.to_csv(\"user_playlist_features_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original rows: {len(df)}, Cleaned rows: {len(df_cleaned)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
